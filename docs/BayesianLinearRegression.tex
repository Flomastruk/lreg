\documentclass[12pt]{article}
\usepackage{amssymb,amsmath,amsthm}
\usepackage{mathtools}

\usepackage{wrapfig, tikz, tikz-cd}
\usetikzlibrary{arrows, arrows, calc, decorations.markings, automata,calc}

\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{colorlinks=false,linkbordercolor=red,linkcolor=green,pdfborderstyle={/S/U/W 2}}

\usepackage{url}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}
\numberwithin{equation}{section}

\newcommand{\dd}{\partial}
\newcommand{\argmax}{\operatorname{argmax}}
\newcommand{\Span}{\operatorname{Span}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\rr}{\text{r}}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}
\newcommand{\eps}{\varepsilon}
\newcommand{\ph}{\varphi}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\BB}{\mathfrak{B}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\SSigma}{\boldsymbol{\Sigma}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\MM}{\mathfrak{M}}
\newcommand{\kk}{\textbf{k}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\VV}{\mathbb{V}}
\newcommand{\II}{\mathbb{I}}
\newcommand{\eq}{\stackrel{\mathclap{\normalfont\text{def}}}{=}}
\newcommand{\convas}{\stackrel{\mathclap{\normalfont\text{as}}}{\longrightarrow}}

\newcommand{\XTX}{X^TX}
\newcommand{\XTXi}{\left(X^TX\right)^{-1}}

\begin{document}
\title{Bayesian Linear Regression}
\author{Efim Abrikosov}
\maketitle

\section{Framework}
\subsection{Notations}

\begin{equation}\label{linear}
    y = x\cdot \bbeta +\varepsilon,\ \varepsilon \sim\mathcal{N}(0,\sigma^2)
\end{equation}

\begin{enumerate}
    \item Individual observations $(x, y) \in \RR^k\times \RR$
    \item Observed data $(X, Y)\in \RR^{n\times k}\times \RR^n$
    \item Linear regression weights $\bbeta \in \RR^k$ 
    \item Observation error variance $\sigma^2$
\end{enumerate}

\subsection{Model Assumptions}
\begin{enumerate}
    \item Observations $x$ have full rank
    \item Observation errors are independent, normally distributed with mean zero and variance $\sigma^2$
    \item Relation \ref{linear} holds
    \item Error variance $\sigma^2$ is either known, or its prior distribution is inverse gamma distribution with parameters $a_0,\ b_0$
    \item $\bbeta$ has a prior distribution $\mathcal{N}(\bbeta_0,\sigma^2\SSigma_0)$
\end{enumerate}

\section{Known Observation Variance with Linear Weights Prior}
\subsection{Summary of Results}
Posterior distribution of $\bbeta$:
\begin{flalign}
    \label{posterior_beta0}&f(\bbeta\mid Y,X)\sim \mathcal{N}(\bbeta_1, \sigma^2\SSigma_1)&&\\
    &\SSigma_1^{-1}=\SSigma_0^{-1}+\XTX &&\\
    &\bbeta_1=\SSigma_1\left(\XTX \widehat\bbeta + \SSigma_0^{-1}\bbeta_0\right)&&\\
    &\widehat{\bbeta}=\XTXi X^TY&&
\end{flalign}
Posterior prediction distribution $\widehat y \equiv x\cdot\bbeta$:
\begin{equation}
    f(\widehat y\mid Y, X, x)\sim \mathcal{N}\left(x\bbeta_1, \sigma^2 x\XTXi x^T\right)
\end{equation}
Posterior observation distribution $\widehat y \equiv x\cdot\bbeta + e$:
\begin{equation}
    f(y\mid Y, X, x)\sim \mathcal{N}\left(x\bbeta_1, \sigma^2\left(1+x\XTXi x^T\right)\right)
\end{equation}
Confidence interval, or $t$-test, for a fixed value $\underline{\smash{\bbeta}}$ and a linear constraint $\boldsymbol{c}\in\RR^k$:
\begin{equation}
    \frac{\boldsymbol{c}(\underline{\smash{\bbeta}}-\bbeta_1)}{\sigma\sqrt{\left(\boldsymbol{c}\SSigma_1 \boldsymbol{c}^T\right)}} \sim \mathcal{N}(0,1)
\end{equation}
Joint $f$-test for a set of linear constraints $\boldsymbol{C}\in\RR^{l \times k}$


\subsection{Uninformative Prior}

\section{Conjugate Priors For Observation Variance and Linear Weights}

\end{document}